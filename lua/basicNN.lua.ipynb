{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'torch'\n",
    "require 'nn'\n",
    "require 'optim'\n",
    "require 'xlua'\n",
    "torch.manualSeed(123)\n",
    "ffi = require('ffi')\n",
    "require \"util\"\n",
    "require \"readRelations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "--LOAD WORD VECTORS\n",
    "\n",
    "--Load custom word2vec word vectors\n",
    "function load_word2vec(w2vpath, inputDim)\n",
    "    local path = w2vpath\n",
    "    local inputDim = inputDim\n",
    "    print('Using custom word vectors')\n",
    "    local ignore = io.open(opt.wordTable,\"r\")\n",
    "    if ignore ~= nil then\n",
    "      io.close(ignore)\n",
    "      return torch.load(opt.wordTable)\n",
    "    end\n",
    "    local word2vec_file = io.open(path)\n",
    "    local word2vec_table = {}\n",
    "\n",
    "    local line = word2vec_file:read(\"*l\")\n",
    "    while line do\n",
    "        -- read the word2vec text file one line at a time, break at EOF\n",
    "        local i = 1\n",
    "        local word = \"\"\n",
    "        for entry in line:gmatch(\"%S+\") do -- split the line at each space\n",
    "            if i == 1 then\n",
    "                -- word comes first in each line, so grab it and create new table entry\n",
    "                word = entry:gsub(\"%p+\", \"\"):lower() -- remove all punctuation and change to lower case\n",
    "                if string.len(word) > 0 then\n",
    "                    word2vec_table[word] = torch.zeros(inputDim, 1) -- padded with an extra dimension for convolution\n",
    "                else\n",
    "                    break\n",
    "                end\n",
    "            else\n",
    "                -- read off and store each word vector element\n",
    "                word2vec_table[word][i-1] = tonumber(entry)\n",
    "            end\n",
    "            i = i+1\n",
    "        end\n",
    "        line = word2vec_file:read(\"*l\")\n",
    "    end\n",
    "    print('Saving dictionary as torch file for later')\n",
    "    torch.save(opt.wordTable, word2vec_table)\n",
    "    return word2vec_table\n",
    "end\n",
    "\n",
    "--Load word vectors using glove or w2v\n",
    "function load_wordVector(wordVectorPath, inputDim, model)\n",
    "    print(\"Start loading word vectors\")\n",
    "    local inputDim = inputDim\n",
    "    local path = wordVectorPath\n",
    "    if model == 'wv' then\n",
    "      return load_word2vec(wordVectorPaht, inputDim)\n",
    "    end\n",
    "    local wordVector_file = io.open(path)\n",
    "    local wordVector_table = {}\n",
    "\n",
    "    local line = wordVector_file:read(\"*l\")\n",
    "    while line do\n",
    "        -- read the wordVector text file one line at a time, break at EOF\n",
    "        local i = 1\n",
    "        local word = \"\"\n",
    "        for entry in line:gmatch(\"%S+\") do -- split the line at each space\n",
    "            if i == 1 then\n",
    "                -- word comes first in each line, so grab it and create new table entry\n",
    "                word = entry:gsub(\"%p+\", \"\"):lower() -- remove all punctuation and change to lower case\n",
    "                if string.len(word) > 0 then\n",
    "                    wordVector_table[word] = torch.zeros(inputDim, 1) -- padded with an extra dimension for convolution\n",
    "                else\n",
    "                    break\n",
    "                end\n",
    "            else\n",
    "                -- read off and store each word vector element\n",
    "                wordVector_table[word][i-1] = tonumber(entry)\n",
    "            end\n",
    "            i = i+1\n",
    "        end\n",
    "        line = wordVector_file:read(\"*l\")\n",
    "    end\n",
    "    \n",
    "    return wordVector_table\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Start loading word vectors\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordVector_table = load_wordVector('data/glove/glove.6B.50d.txt', 50, 'glove')\n",
    "\n",
    "print 'Done reading glove vectors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  0 : per:country_of_death\n",
       "  1 : per:schools_attended\n",
       "  2 : per:other_family\n",
       " "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       " 3 : per:city_of_birth\n",
       "  4 : org:top_members/employees\n",
       "  5 : org:founded_by\n",
       "  6 : per:stateorprovinces_of_residence\n",
       "  7 : per:parents\n",
       "  8 : per:stateorprovince_of_death\n",
       "  9 : org:website\n",
       "  10 : per:stateorprovince_of_birth\n",
       "  11 : org:political/religious_affiliation\n",
       "  12 : per:age\n",
       "  13 : per:date_of_birth\n",
       "  14 : per:title\n",
       "  15 : per:member_of\n",
       "  16 : org:members\n",
       "  17 : org:city_of_headquarters\n",
       "  18 : per:origin\n",
       "  19 : per:alternate_names\n",
       "  20 : per:date_of_death\n",
       "  21 : per:children\n",
       "  22 : org:stateorprovince_of_headquarters\n",
       "  23 : org:member_of\n",
       "  24 : org:subsidiaries\n",
       "  25 : org:alternate_names\n",
       "  26 : per:religion\n",
       "  27 : per:spouse\n",
       "  28 : per:siblings\n",
       "  29 : per:cities_of_residence\n",
       "  30 : per:countries_of_residence\n",
       "  31 : org:country_of_headquarters\n",
       "  32 : org:number_of_employees/members\n",
       "  33 : per:cause_of_death\n",
       "  34 : per:charges\n",
       "  35 : org:shareholders\n",
       "  36 : per:country_of_birth\n",
       "  37 : per:employee_of\n",
       "  38 : org:dissolved\n",
       "  39 : org:parents\n",
       "  40 : org:founded\n",
       "  41 : per:city_of_death\n",
       "}\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- function processLine(line)\n",
    "--     -- split the line by tab\n",
    "--     vals = util.split(line, \"\\t\")\n",
    "--     tokens = util.split(vals[1], \",\")\n",
    "--     relations = util.split(vals[2], \",\")\n",
    "-- end\n",
    "\n",
    "--datafile = '../data/train/processed/train_processed_10.tsv'\n",
    "\n",
    "--a, b = util.readDataFile(datafile, util.parseProcessedLine)\n",
    "read_relations('../data/relations.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
